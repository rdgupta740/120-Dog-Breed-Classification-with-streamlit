{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0Bp5EKAc2X4i"
   },
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gKi0zr-j6JfO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import itertools\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'D:/ratan/dog breeds/Images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtoG1bsGBs5T",
    "outputId": "53a025de-f259-4925-ae98-a0ff0c2b2858"
   },
   "source": [
    "dir_path = 'D:/ratan/dog breeds/Images'\n",
    "#print(os.listdir(dir_path))\n",
    "for file in os.listdir(dir_path):\n",
    "  new = os.rename(dir_path + '/' + file, dir_path + '/' + file.split('-')[1])\n",
    "  \n",
    "for file in os.listdir(dir_path):\n",
    "  print(file, ':', len(os.listdir(dir_path + '/' + file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0nVbRvgZ61gJ"
   },
   "outputs": [],
   "source": [
    "for file in os.listdir(dir_path):\n",
    "  j = 1\n",
    "  for i in os.listdir(dir_path + '/' + file):\n",
    "    os.rename(dir_path + '/' + file  + '/' + i, dir_path + '/' + file + '/' + (file + '_' + str(j)) + '.jpg')\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jo855ukcuSmw"
   },
   "outputs": [],
   "source": [
    "\n",
    "os.mkdir('D:/ratan/dog breeds/train')\n",
    "os.mkdir('D:/ratan/dog breeds/valid')\n",
    "os.mkdir('D:/ratan/dog breeds/test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ah8d4UNPzcv7"
   },
   "outputs": [],
   "source": [
    "for file in os.listdir(dir_path):\n",
    "  os.mkdir('D:/ratan/dog breeds/train' + '/' + file)\n",
    "  os.mkdir('D:/ratan/dog breeds/valid' + '/' + file)\n",
    "  os.mkdir('D:/ratan/dog breeds/test' + '/' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V84XeK2FCXbm"
   },
   "source": [
    "os.chdir(dir_path)\n",
    "for file in os.listdir(dir_path):\n",
    "  for c in random.sample(glob.glob(file + '/' + file + '*'), 30):\n",
    "    shutil.move(c, '/content/dog_breed/train' + '/' + file)\n",
    "  for c in random.sample(glob.glob(file + '/' + file + '*'), 5):\n",
    "    shutil.move(c, '/content/dog_breed/test' + '/' + file)\n",
    "  for c in random.sample(glob.glob(file + '/' + file + '*'), 8):\n",
    "    shutil.move(c, '/content/dog_breed/valid' + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2xRPnTDHv49k"
   },
   "outputs": [],
   "source": [
    "os.chdir(dir_path)\n",
    "for file in os.listdir(dir_path):\n",
    "  total = len(os.listdir(dir_path + '/' + file))\n",
    "  for c in random.sample(glob.glob(file + '/' + file + '*'), round(0.2*total)):\n",
    "    shutil.move(c, 'D:/ratan/dog breeds/train' + '/' + file)\n",
    "  for c in random.sample(glob.glob(file + '/' + file + '*'), round(0.02*total)):\n",
    "    shutil.move(c, 'D:/ratan/dog breeds/test' + '/' + file)\n",
    "  for c in random.sample(glob.glob(file + '/' + file + '*'), round(0.02*total)):\n",
    "    shutil.move(c, 'D:/ratan/dog breeds/valid' + '/' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WV1tYA0G34hs"
   },
   "outputs": [],
   "source": [
    "train_dir = 'D:/ratan/dog breeds/train'\n",
    "test_dir = 'D:/ratan/dog breeds/test'\n",
    "valid_dir = 'D:/ratan/dog breeds/valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOFln7Ma4IoA"
   },
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function= tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory = train_path, target_size = (224, 224), batch_size = 10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function= tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory = test_path, target_size = (224, 224), batch_size = 10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function= tf.keras.applications.mobilenet.preprocess_input).flow_from_directory(directory = valid_path, target_size = (224, 224), batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baLaeFyT5IBf"
   },
   "source": [
    "imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vm8c7RuW5fY2"
   },
   "source": [
    "def plot_images(image_arr):\n",
    "  fig, axes = plt.subplots(1, 10, figsize = (20, 20))\n",
    "  axes = axes.flatten()\n",
    "  for image, ax in zip(image_arr, axes):\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wq9-kU1E6QuR"
   },
   "source": [
    "plot_images(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JlDnp5us8WBb"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "def create_data_loaders(train_dir, valid_dir, test_dir, image_size=IMG_SIZE):\n",
    "  \"\"\"\n",
    "  Creates a training and test image BatchDataset from train_dir and test_dir.\n",
    "  \"\"\"\n",
    "  train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                  label_mode=\"categorical\",\n",
    "                                                                  image_size=image_size)\n",
    "  valid_data = tf.keras.preprocessing.image_dataset_from_directory(valid_dir,\n",
    "                                                                  label_mode=\"categorical\",\n",
    "                                                                  image_size=image_size)\n",
    "  # Note: the test data is the same as the previous experiment, we could\n",
    "  # skip creating this, but we'll leave this here to practice.\n",
    "  test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                  label_mode=\"categorical\",\n",
    "                                                                  image_size=image_size)\n",
    "  \n",
    "  return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "q2nhbVc58aRN"
   },
   "outputs": [],
   "source": [
    "# Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
    "data_augmentation = keras.Sequential([\n",
    "  preprocessing.RandomFlip(\"horizontal\"),\n",
    "  preprocessing.RandomRotation(0.2),\n",
    "  preprocessing.RandomZoom(0.2),\n",
    "  preprocessing.RandomHeight(0.2),\n",
    "  preprocessing.RandomWidth(0.2),\n",
    "  # preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetB0\n",
    "], name =\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Blxa6h1J8zIA",
    "outputId": "a7502ca2-22fa-4791-bc21-697b44b38f67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16705208/16705208 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "BASE_MODEL = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "\n",
    "def create_model(input_shape=INPUT_SHAPE, base_model=BASE_MODEL, num_classes=10):\n",
    "  # Fine-tune?\n",
    "  base_model.trainable = False\n",
    "\n",
    "  # Create input layer\n",
    "  inputs = layers.Input(shape=input_shape, name=\"input_layer\")\n",
    "\n",
    "  # Add in data augmentation Sequential model as a layer\n",
    "  x = data_augmentation(inputs)\n",
    "\n",
    "  # Give base_model inputs (after augmentation) and don't train it\n",
    "  x = base_model(x, training=False)\n",
    "\n",
    "  # Pool output features of base model\n",
    "  x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
    "\n",
    "  # Put a dense layer on as the output\n",
    "  outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "  # Make a model with inputs and outputs\n",
    "  model = keras.Model(inputs, outputs)\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "D8Xq_ukM9Kak"
   },
   "outputs": [],
   "source": [
    "def load_and_prep_image(filename, img_shape=224, scale=False):\n",
    "  \"\"\"\n",
    "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
    "  (224, 224, 3).\n",
    "  \"\"\"\n",
    "  # Read in the image\n",
    "  img = tf.io.read_file(filename)\n",
    "  # Decode it into a tensor\n",
    "  img = tf.image.decode_jpeg(img)\n",
    "  # Resize the image\n",
    "  img = tf.image.resize(img, [img_shape, img_shape])\n",
    "  # Rescale the image (get all values between 0 and 1)\n",
    "  if scale:\n",
    "    return img/255.\n",
    "  else:\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QtdwKUwD9ciJ",
    "outputId": "d8d216ba-f3eb-47a7-8366-e45550fd1def"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4111 files belonging to 120 classes.\n",
      "Found 406 files belonging to 120 classes.\n",
      "Found 406 files belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data = create_data_loaders(train_dir=train_dir, valid_dir = valid_dir, test_dir = test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nvg1-M7k7geG"
   },
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Conv2D, Flatten, MaxPool2D, BatchNormalization, Dropout, Softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.applications.mobilenet import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqdv3mdg8ev2",
    "outputId": "a9675eda-9376-4063-cc10-4de1ac1cb855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " data_augmentation (Sequenti  (None, 224, 224, 3)      0         \n",
      " al)                                                             \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n",
      "                                                                 \n",
      " global_average_pooling_laye  (None, 1280)             0         \n",
      " r (GlobalAveragePooling2D)                                      \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 120)               153720    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,203,291\n",
      "Trainable params: 153,720\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "129/129 [==============================] - 770s 6s/step - loss: 3.1167 - accuracy: 0.3746 - val_loss: 1.6012 - val_accuracy: 0.6771\n",
      "Epoch 2/5\n",
      "129/129 [==============================] - 784s 6s/step - loss: 1.4901 - accuracy: 0.6757 - val_loss: 0.9026 - val_accuracy: 0.8021\n",
      "Epoch 3/5\n",
      "129/129 [==============================] - 773s 6s/step - loss: 1.0772 - accuracy: 0.7512 - val_loss: 0.7575 - val_accuracy: 0.8229\n",
      "Epoch 4/5\n",
      "129/129 [==============================] - 733s 6s/step - loss: 0.8859 - accuracy: 0.7862 - val_loss: 0.6160 - val_accuracy: 0.8542\n",
      "Epoch 5/5\n",
      "129/129 [==============================] - 593s 5s/step - loss: 0.7358 - accuracy: 0.8302 - val_loss: 0.6716 - val_accuracy: 0.8229\n"
     ]
    }
   ],
   "source": [
    "model_1 = create_model(num_classes=len(train_data.class_names))\n",
    "model_1.summary()\n",
    "# Fit the model\n",
    "history_1_percent = model_1.fit(train_data,\n",
    "                    epochs=5,\n",
    "                    steps_per_epoch=len(train_data),\n",
    "                    validation_data=valid_data,\n",
    "                    validation_steps=int(0.25 * len(valid_data)), # validate for less steps\n",
    "                    # Track model training logs\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mg7XgN_1-WH4"
   },
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHNqREDN-zFW"
   },
   "source": [
    "history = model.fit(x= train_batches, validation_data= valid_batches, epochs = 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOAx9reVJW8I"
   },
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwfSDa-HcRA1"
   },
   "source": [
    "pred = model.predict(test_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM0970CekGhV"
   },
   "source": [
    "label = decode_predictions(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJOF_4j8hUhQ"
   },
   "source": [
    "pred = np.argmax(pred, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3MW9u5bLkFOE",
    "outputId": "7e171862-55c6-4a45-c017-29704658a62d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Afghan_hound',\n",
       " 'African_hunting_dog',\n",
       " 'Airedale',\n",
       " 'American_Staffordshire_terrier',\n",
       " 'Appenzeller',\n",
       " 'Australian_terrier',\n",
       " 'Bedlington_terrier',\n",
       " 'Bernese_mountain_dog',\n",
       " 'Blenheim_spaniel',\n",
       " 'Border_collie',\n",
       " 'Border_terrier',\n",
       " 'Boston_bull',\n",
       " 'Bouvier_des_Flandres',\n",
       " 'Brabancon_griffon',\n",
       " 'Brittany_spaniel',\n",
       " 'Cardigan',\n",
       " 'Chesapeake_Bay_retriever',\n",
       " 'Chihuahua',\n",
       " 'Dandie_Dinmont',\n",
       " 'Doberman',\n",
       " 'English_foxhound',\n",
       " 'English_setter',\n",
       " 'English_springer',\n",
       " 'EntleBucher',\n",
       " 'Eskimo_dog',\n",
       " 'French_bulldog',\n",
       " 'German_shepherd',\n",
       " 'German_short',\n",
       " 'Gordon_setter',\n",
       " 'Great_Dane',\n",
       " 'Great_Pyrenees',\n",
       " 'Greater_Swiss_Mountain_dog',\n",
       " 'Ibizan_hound',\n",
       " 'Irish_setter',\n",
       " 'Irish_terrier',\n",
       " 'Irish_water_spaniel',\n",
       " 'Irish_wolfhound',\n",
       " 'Italian_greyhound',\n",
       " 'Japanese_spaniel',\n",
       " 'Kerry_blue_terrier',\n",
       " 'Labrador_retriever',\n",
       " 'Lakeland_terrier',\n",
       " 'Leonberg',\n",
       " 'Lhasa',\n",
       " 'Maltese_dog',\n",
       " 'Mexican_hairless',\n",
       " 'Newfoundland',\n",
       " 'Norfolk_terrier',\n",
       " 'Norwegian_elkhound',\n",
       " 'Norwich_terrier',\n",
       " 'Old_English_sheepdog',\n",
       " 'Pekinese',\n",
       " 'Pembroke',\n",
       " 'Pomeranian',\n",
       " 'Rhodesian_ridgeback',\n",
       " 'Rottweiler',\n",
       " 'Saint_Bernard',\n",
       " 'Saluki',\n",
       " 'Samoyed',\n",
       " 'Scotch_terrier',\n",
       " 'Scottish_deerhound',\n",
       " 'Sealyham_terrier',\n",
       " 'Shetland_sheepdog',\n",
       " 'Shih',\n",
       " 'Siberian_husky',\n",
       " 'Staffordshire_bullterrier',\n",
       " 'Sussex_spaniel',\n",
       " 'Tibetan_mastiff',\n",
       " 'Tibetan_terrier',\n",
       " 'Walker_hound',\n",
       " 'Weimaraner',\n",
       " 'Welsh_springer_spaniel',\n",
       " 'West_Highland_white_terrier',\n",
       " 'Yorkshire_terrier',\n",
       " 'affenpinscher',\n",
       " 'basenji',\n",
       " 'basset',\n",
       " 'beagle',\n",
       " 'black',\n",
       " 'bloodhound',\n",
       " 'bluetick',\n",
       " 'borzoi',\n",
       " 'boxer',\n",
       " 'briard',\n",
       " 'bull_mastiff',\n",
       " 'cairn',\n",
       " 'chow',\n",
       " 'clumber',\n",
       " 'cocker_spaniel',\n",
       " 'collie',\n",
       " 'curly',\n",
       " 'dhole',\n",
       " 'dingo',\n",
       " 'flat',\n",
       " 'giant_schnauzer',\n",
       " 'golden_retriever',\n",
       " 'groenendael',\n",
       " 'keeshond',\n",
       " 'kelpie',\n",
       " 'komondor',\n",
       " 'kuvasz',\n",
       " 'malamute',\n",
       " 'malinois',\n",
       " 'miniature_pinscher',\n",
       " 'miniature_poodle',\n",
       " 'miniature_schnauzer',\n",
       " 'otterhound',\n",
       " 'papillon',\n",
       " 'pug',\n",
       " 'redbone',\n",
       " 'schipperke',\n",
       " 'silky_terrier',\n",
       " 'soft',\n",
       " 'standard_poodle',\n",
       " 'standard_schnauzer',\n",
       " 'toy_poodle',\n",
       " 'toy_terrier',\n",
       " 'vizsla',\n",
       " 'whippet',\n",
       " 'wire']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_data.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiODTxM-YVdd"
   },
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0cgsOFeY-Kr"
   },
   "source": [
    "test_batches.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdYluzzFY0Ly"
   },
   "source": [
    "test_batches.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB78zekBYagx"
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(pred, test_batches.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLBc3CvoWPiB"
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "result = imagenet_utils.decode_predictions(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u5PxULHu3Tb6",
    "outputId": "2edc36b5-f76d-4a6b-de69-91107ca6f180"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
       "array([[[ 53.979595 ,  60.214287 ,   6.214286 ],\n",
       "        [ 57.224487 ,  62.224487 ,   7.795917 ],\n",
       "        [ 59.08673  ,  62.08673  ,   8.65816  ],\n",
       "        ...,\n",
       "        [138.1986   , 148.1986   ,  77.19859  ],\n",
       "        [137.648    , 147.648    ,  76.648    ],\n",
       "        [137.       , 147.42822  ,  76.21411  ]],\n",
       "\n",
       "       [[ 49.280613 ,  56.280613 ,   4.280612 ],\n",
       "        [ 54.22959  ,  58.22959  ,   7.2295923],\n",
       "        [ 55.642857 ,  59.642857 ,   8.642858 ],\n",
       "        ...,\n",
       "        [137.95418  , 147.95418  ,  76.95417  ],\n",
       "        [137.77039  , 147.77039  ,  76.770386 ],\n",
       "        [137.71933  , 148.14755  ,  76.93343  ]],\n",
       "\n",
       "       [[ 48.87245  ,  56.87245  ,   5.872451 ],\n",
       "        [ 50.714287 ,  57.714287 ,   6.714287 ],\n",
       "        [ 50.92857  ,  57.92857  ,   6.92857  ],\n",
       "        ...,\n",
       "        [138.20877  , 148.20877  ,  75.20878  ],\n",
       "        [140.23973  , 150.23973  ,  77.23973  ],\n",
       "        [137.94386  , 147.94386  ,  76.94386  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 53.857124 ,  60.285698 ,  12.071411 ],\n",
       "        [ 52.       ,  58.       ,  12.       ],\n",
       "        [ 48.93367  ,  55.93367  ,  11.933671 ],\n",
       "        ...,\n",
       "        [231.92859  , 206.92859  , 176.92859  ],\n",
       "        [231.71423  , 205.71423  , 178.71423  ],\n",
       "        [226.78589  , 194.41293  , 161.35693  ]],\n",
       "\n",
       "       [[ 55.785713 ,  61.785713 ,  13.785714 ],\n",
       "        [ 52.71432  ,  58.71432  ,  12.714321 ],\n",
       "        [ 49.92857  ,  57.92857  ,  10.92857  ],\n",
       "        ...,\n",
       "        [230.33171  , 203.33171  , 176.33171  ],\n",
       "        [231.58678  , 204.58678  , 177.58678  ],\n",
       "        [229.       , 198.21411  , 169.42822  ]],\n",
       "\n",
       "       [[ 56.045906 ,  61.908184 ,  13.954093 ],\n",
       "        [ 53.214233 ,  59.214233 ,  11.214233 ],\n",
       "        [ 50.80107  ,  58.80107  ,  11.801069 ],\n",
       "        ...,\n",
       "        [230.78577  , 203.78577  , 174.57153  ],\n",
       "        [231.57141  , 201.35718  , 173.14294  ],\n",
       "        [229.2601   , 199.83163  , 169.95413  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = load_and_prep_image(\"C:/Users/User PC/Desktop/123.jpg\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "royzIlPl3boP",
    "outputId": "0c0e2d26-6373-46b2-f7a6-7f8edec4217d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.36938776e-04, 1.39096592e-04, 2.61792418e-04, 6.53315242e-03,\n",
       "        8.09192308e-04, 2.21443224e-05, 6.78232391e-05, 1.76869125e-05,\n",
       "        1.35027340e-05, 2.74258109e-05, 1.82349072e-03, 5.53726295e-06,\n",
       "        2.86477571e-05, 1.33318943e-03, 7.16077862e-04, 1.65872858e-04,\n",
       "        1.75972991e-02, 3.81219666e-04, 1.52644789e-04, 1.20712015e-04,\n",
       "        1.29981153e-03, 5.84774127e-04, 7.07322943e-06, 1.01814359e-04,\n",
       "        5.79978514e-04, 3.69846704e-04, 5.26519318e-04, 2.35891843e-04,\n",
       "        6.94224145e-05, 5.15761180e-03, 4.81878582e-04, 4.59183793e-04,\n",
       "        1.86408201e-04, 1.12814130e-04, 4.06467792e-04, 4.72892716e-05,\n",
       "        1.38650794e-04, 2.97934403e-05, 2.07548692e-05, 8.78432729e-06,\n",
       "        7.29226649e-01, 2.02203562e-04, 2.48255744e-03, 9.33699775e-05,\n",
       "        1.92005173e-05, 1.59977608e-05, 5.13698731e-04, 1.01637689e-03,\n",
       "        4.66044949e-05, 3.09260213e-04, 6.27199624e-05, 1.35445400e-04,\n",
       "        7.27606937e-04, 2.07219000e-05, 3.40403877e-02, 6.83011347e-03,\n",
       "        2.01066537e-03, 1.74954382e-03, 1.20900559e-05, 2.01012554e-05,\n",
       "        5.36613197e-06, 6.44779939e-05, 1.44066453e-05, 4.25469334e-05,\n",
       "        1.40697826e-04, 6.53836294e-04, 1.61708871e-04, 2.51515768e-03,\n",
       "        1.35688460e-04, 3.15078162e-03, 7.93997548e-04, 3.49711263e-05,\n",
       "        1.23601540e-05, 3.18365928e-05, 1.20581362e-05, 2.96590097e-05,\n",
       "        7.26240221e-04, 4.10021609e-03, 1.16354844e-03, 1.75078902e-02,\n",
       "        1.02014186e-04, 8.51395234e-05, 4.95279266e-04, 1.74043016e-05,\n",
       "        3.59642245e-02, 1.19550841e-05, 2.89448141e-03, 5.99213061e-04,\n",
       "        4.48003033e-04, 3.19857136e-05, 4.08624706e-04, 2.56647239e-04,\n",
       "        6.61910186e-03, 8.08401674e-04, 2.57262436e-04, 3.99212614e-02,\n",
       "        3.84380219e-05, 2.24799737e-06, 1.24559749e-03, 2.50402609e-05,\n",
       "        1.15097628e-03, 3.46114648e-05, 7.40614487e-04, 2.17926819e-04,\n",
       "        5.30923971e-05, 1.48634508e-05, 9.06664762e-04, 7.78255708e-06,\n",
       "        3.20860330e-04, 3.97736244e-02, 7.63149365e-05, 1.29724867e-04,\n",
       "        1.03509019e-03, 3.48057831e-04, 7.30135434e-05, 6.20948049e-05,\n",
       "        9.55910218e-05, 1.23834051e-02, 3.09977011e-04, 2.22837189e-05]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded = tf.expand_dims(img, axis=0) # expand image dimensions (224, 224, 3) -> (1, 224, 224, 3)\n",
    "pred = model_1.predict(expanded)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "PbdGUKgm3moC",
    "outputId": "93931c47-4c53-433c-a02e-68641967205a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Labrador_retriever'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[tf.argmax(pred[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "mBHTUQqS36ZQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/User PC\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/User PC\\assets\n"
     ]
    }
   ],
   "source": [
    "model_1.save(\"C:/Users/User PC\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
